{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aece326c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regressione non Lineare (parte 2)\n",
    "\n",
    "**Programmazione di Applicazioni Data Intensive**  \n",
    "Laurea in Ingegneria e Scienze Informatiche  \n",
    "DISI - Università di Bologna, Cesena\n",
    "\n",
    "Proff. Gianluca Moro, Roberto Pasolini  \n",
    "`nome.cognome@unibo.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47e35f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "- Importare i package necessari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813db470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72681c05",
   "metadata": {},
   "source": [
    "- In Jupyter, configurare l'output di matplotlib integrato nel notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469e759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e9f44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di studio: Predizione dei prezzi delle case\n",
    "\n",
    "- Riprendiamo dalla scorsa esercitazione il dataset relativo ai prezzi delle case\n",
    "- Forniamo tale dataset all'URL https://git.io/fjGjx già adattato per essere caricato con `read_csv` con le opzioni di default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0902d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if not os.path.exists(\"housing.csv\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(\"https://git.io/fjGjx\", \"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b83b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7253b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lista delle variabili\n",
    "\n",
    "- CRIM: tasso di criminalità pro capite per zona\n",
    "- ZN: proporzione terreno residenziale per lotti maggiori di 25.000 piedi quadrati (circa 2300 m2)\n",
    "- INDUS: proporzione di acri industriali non commerciali per città\n",
    "- CHAS: variabile fittizia Charles River, 1 se il tratto affianca il fiume, altrimenti 0\n",
    "- NOX: concentrazione di ossido d’azoto (parti per 10 milioni)\n",
    "- RM: numero medio di stanze per abitazione\n",
    "- AGE: proporzione delle unità abitate costruite prima del 1940\n",
    "- DIS: distanze pesate verso i cinque uffici di collocamento di Boston\n",
    "- RAD: indice di accessibilità rispetto alle grandi vie radiali di comunicazione\n",
    "- TAX: tasso di imposte sulla casa per 10.000 dollari\n",
    "- PTRATIO: rapporto allievi-docenti per città\n",
    "- B: 1000(Bk - 0.63)2, dove Bk è la proporzione di persone di origine afroamericana\n",
    "- LSTAT: percentuale di popolazione con basso reddito\n",
    "- **MEDV: valore mediano delle abitazioni di proprietà in migliaia di dollari**\n",
    "  - vogliamo stimare il valore di questa variabile in funzione delle altre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd2fe70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74324999",
   "metadata": {},
   "source": [
    "- Estraiamo dal frame\n",
    "  - la serie `y` con i valori della variabile `MEDV` da prevedere\n",
    "  - il frame `X` con i valori di tutte le altre variabili, utilizzabili per la predizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bbfcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = housing[\"MEDV\"]\n",
    "X = housing.drop(columns=\"MEDV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a083fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Divisione tra training e validation set\n",
    "\n",
    "- Dividiamo i dati caricati casualmente in\n",
    "  - un _training set_ per addestrare i modelli\n",
    "  - un _validation set_ disgiunto su cui verificare l'accuratezza del modello\n",
    "- Usiamo la funzione `train_test_split` di scikit-learn\n",
    "  - con `test_size` indichiamo quanti dati vanno nel validation set, i restanti andranno nel training set\n",
    "  - con `random_state` fissiamo un seed per la suddivisione casuale\n",
    "  - la funzione mescola i dati di `X` e `y` in modo congiunto, mantenendo la corrispondenza esistente tra le posizioni dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c8765c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7434291",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Funzioni per la validazione\n",
    "\n",
    "- Riprendiamo dalla prima parte le funzioni per estrarre e stampare le misure di valutazione del modello (MSE, errore relativo, R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b25381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importo MSE e R²\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# definisco funzione per errore relativo\n",
    "def relative_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "# funzione per calcolare e stampare tutte e tre\n",
    "def print_eval(X, y, model):\n",
    "    preds = model.predict(X)\n",
    "    print(\"   Mean squared error: {:.5}\".format(mean_squared_error(y, preds)))\n",
    "    print(\"       Relative error: {:.5%}\".format(relative_error(y, preds)))\n",
    "    print(\"R-squared coefficient: {:.5}\".format(r2_score(y, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be6f7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 1: Ripasso modelli\n",
    "\n",
    "Addestrare sul training set creato sopra tre modelli diversi con le seguenti configurazioni, per ciascuno stampare le misure di valutazione sul validation set e i coefficienti associati a ciascuna variabile\n",
    "\n",
    "- **(1a)** regressione lineare semplice\n",
    "- **(1b)** regressione lineare con regolarizzazione L2 (regressione ridge), assumendo $\\alpha=1$\n",
    "- **(1c)** regressione lineare con standardizzazione delle feature\n",
    "\n",
    "Infine:\n",
    "\n",
    "- **(1d)** visualizzare in un unico frame i coefficienti di tutti e tre i modelli (una riga per variabile, una colonna per modello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d2a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sono eseguiti quì tutti gli import necessari da scikit-learn\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e8985",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In tutti e tre i modelli, dai segni dei coefficienti possiamo vedere quali fenomeni influiscono positivamente e negativamente sul prezzo\n",
    "  - ad es. il prezzo delle case è più alto se vicine al fiume (`CHAS`), mentre decresce con la criminalità (`CRIM`)\n",
    "- Nella regressione ridge i valori assoluti più alti sono ridotti (es. `NOX` e `RM`)\n",
    "- Con la standardizzazione delle feature otteniamo valori su scale simili, che possiamo confrontare alla pari\n",
    "  - ad es. negli altri modelli il coefficiente di `NOX` è alto perché i valori di tale variabile sono bassi (la media è circa 0.55, contro quelle superiori a 3 delle altre variabili)\n",
    "  - nel modello con standardizzazione assumono invece più peso il numero di stanze (`RM`) e la distanza dagli uffici di collocamento (`DIS`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdf702",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione Lasso\n",
    "\n",
    "- La regolarizzazione L2 impedisce che i parametri del modello assumano valori troppo alti\n",
    "- I valori dei parametri sono comunque tutti non nulli, tutte le variabili vengono coinvolte nella predizione\n",
    "- Vorremmo addestrare un modello meno complesso, dove alcuni parametri hanno valori nulli, **ignorando completamente le variabili meno rilevanti**\n",
    "  - ad es. variabili con valori dipendenti da altre (_multicollinearità_)\n",
    "- Questo si può ottenere tramite la regolarizzazione L1, basata sulla norma 1, definita su un vettore $\\mathbf{x}$ di $n$ elementi come\n",
    "$$ \\left\\Vert\\mathbf{x}\\right\\Vert_1 = \\sum_{i=1}^n{\\left\\vert x_i\\right\\vert} = \\left\\vert x_1\\right\\vert+\\ldots+\\left\\vert x_n\\right\\vert $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38872a7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La regressione _lasso_ consiste nella regressione lineare con regolarizzazione L1, basata quindi sul minimizzare la funzione d'errore\n",
    "$$ E = \\frac{1}{2m}\\left\\Vert\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right\\Vert_2^2 + \\alpha\\left\\Vert\\mathbf{\\theta}\\right\\Vert_1 $$\n",
    "- Come per la regressione ridge, il parametro $\\alpha$ controlla il peso della regolarizzazione\n",
    "- La regressione lasso si esegue usando un modello `Lasso`, su cui possiamo impostare come in `Ridge` il parametro `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b11914a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('regr', Lasso(alpha=1))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", Lasso(alpha=1))\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a4f434",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Vediamo i coefficienti del modello risultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b50a2095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.000000\n",
       "ZN         0.000000\n",
       "INDUS     -0.000000\n",
       "CHAS       0.270752\n",
       "NOX       -0.000000\n",
       "RM         2.641503\n",
       "AGE       -0.000000\n",
       "DIS       -0.000000\n",
       "RAD       -0.000000\n",
       "TAX       -0.000000\n",
       "PTRATIO   -1.200172\n",
       "B          0.311046\n",
       "LSTAT     -3.814854\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.named_steps[\"regr\"].coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902eb08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La regolarizzazione L1 ha contribuito ad annullare quanti più coefficienti possibile, creando un modello che considera solo 5 variabili\n",
    "- Ma qual'è l'accuratezza di tale modello?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "999d0ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 25.984\n",
      "       Relative error: 19.41638%\n",
      "R-squared coefficient: 0.65457\n"
     ]
    }
   ],
   "source": [
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134c107",
   "metadata": {},
   "source": [
    "- L'accuratezza è peggiore rispetto ai casi precedenti: in questo caso la regolarizzazione è stata quindi eccessiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27208a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede diminuendo il parametro `alpha`, ovvero il peso della regolarizzazione?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2918cd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('regr', Lasso(alpha=0.2))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", Lasso(alpha=0.2)) # <-- cambiato da 1\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "190c4fec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.394705\n",
       "ZN         0.192948\n",
       "INDUS     -0.000000\n",
       "CHAS       0.827011\n",
       "NOX       -0.812358\n",
       "RM         2.944153\n",
       "AGE       -0.000000\n",
       "DIS       -1.514910\n",
       "RAD        0.000000\n",
       "TAX       -0.000000\n",
       "PTRATIO   -1.698942\n",
       "B          0.842742\n",
       "LSTAT     -4.009724\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.named_steps[\"regr\"].coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be49543",
   "metadata": {},
   "source": [
    "- I coefficienti non nulli sono aumentati da 5 a 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f5af10f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 22.527\n",
      "       Relative error: 16.62391%\n",
      "R-squared coefficient: 0.70053\n"
     ]
    }
   ],
   "source": [
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740e108",
   "metadata": {},
   "source": [
    "- L'accuratezza è di poco inferiore a quella ottenuta con gli altri modelli\n",
    "- Questo modello richiede però solo 9 variabili invece di 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf55fdb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Elastic Net\n",
    "\n",
    "- La regressione _elastic net_ combina insieme le regolarizzazioni L2 e L1 usate in ridge e lasso\n",
    "- Si applica in scikit-learn tramite la classe `ElasticNet`, per cui l'errore è calcolato come:\n",
    "$$ E = \\underbrace{\\frac{1}{2m} ||X\\theta - y||_2 ^ 2}_{\\text{errore sui dati}} + \\underbrace{\\alpha \\rho ||\\theta||_1}_{\\text{L1}} + \\underbrace{\\frac{\\alpha(1-\\rho)}{2} ||\\theta||_2 ^ 2}_{\\text{L2}} $$\n",
    "- I parametri impostabili sono\n",
    "  - `alpha` ($\\alpha$) che determina il peso generale della regolarizzazione\n",
    "  - `l1_ratio` ($\\rho$, compreso tra 0 e 1) che determina il peso di L1 relativo al totale (con $\\rho=1$ si ha la regressione lasso, con $\\rho=0$ la ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4127b58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 22.092\n",
      "       Relative error: 16.18298%\n",
      "R-squared coefficient: 0.70631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = Pipeline([\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"regr\", ElasticNet(alpha=0.2, l1_ratio=0.1))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf3315",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 2: Elastic Net con pesi separati\n",
    "\n",
    "- **(2a)** Definire una funzione `elastic_net_with_alphas` che restituisca un modello elastic net (non addestrato) con pesi dati separatamente per la regolarizzazione L2 e L1\n",
    "  - si ricordi che il parametro `alpha` è la somma dei due pesi\n",
    "- **(2b)** Servendosi di tale funzione, addestrare e validare un modello elastic net con $\\alpha_{L2}=1, \\alpha_{L1}=0.1$ e standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e3c18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_with_alphas(alpha_l2, alpha_l1):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebf9fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ripasso: Regressione polinomiale univariata\n",
    "\n",
    "- Abbiamo visto in precedenza la regressione polinomiale su una sola variabile $X$ (univariata), corrispondente alla regressione lineare sulle variabili $X,X^2,X^3,\\ldots$\n",
    "- Per generare queste variabili utilizziamo il filtro `PolynomialFeatures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad28a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf7ebc",
   "metadata": {},
   "source": [
    "- Siano date ad esempio due osservazioni di una variabile..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7fd5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([ [ 2],\n",
    "                    [-3] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0bd2ed",
   "metadata": {},
   "source": [
    "- Possiamo ottenere ad es. le potenze fino al 4° grado\n",
    "  - `include_bias=True` specifica di non includere il termine di grado 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad4c5740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   4.,   8.,  16.],\n",
       "       [ -3.,   9., -27.,  81.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(sample)\n",
    "#         X   X^2   X^3   X^4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f96111",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione polinomiale multivariata\n",
    "\n",
    "- In presenza di più di una variabile, la regressione polinomiale genera tutti i possibili termini fino al grado impostato, includendo anche **termini basati su più variabili**\n",
    "- Vediamo un esempio con 2 generiche variabili $A$ e $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c0239bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                     A   B\n",
    "sample = np.array([ [ 2, -3],\n",
    "                    [ 4, -5] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc16ac",
   "metadata": {},
   "source": [
    "- Applicando il filtro `PolynomialFeatures` con grado 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "724d2364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,  -3.,   4.,  -6.,   9.],\n",
       "       [  4.,  -5.,  16., -20.,  25.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(sample)\n",
    "#         A     B    A^2   A*B   B^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047ed4c",
   "metadata": {},
   "source": [
    "- Le variabili generate (escludendo il grado nullo) sono 5: $A,B,A^2,AB,B^2$\n",
    "- Oltre ai quadrati delle singole variabili abbiamo quindi anche i prodotti tra di esse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb3f0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo usare il metodo `get_feature_names` del filtro per avere una lista delle variabili calcolate\n",
    "  - il filtro deve già essere stato \"addestrato\" con `fit` o `fit_transform`\n",
    "  - è possibile passare una lista di nomi delle variabili originali, altrimenti sono usati `x0`, `x1`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fd76b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x0', 'x1', 'x0^2', 'x0 x1', 'x1^2']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a03c33c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'A^2', 'A B', 'B^2']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae27814",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando il grado massimo, le variabili generate **aumentano rapidamente**\n",
    "- Ad esempio, aumentando il grado da 2 a 3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fafffdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2.,   -3.,    4.,   -6.,    9.,    8.,  -12.,   18.,  -27.],\n",
       "       [   4.,   -5.,   16.,  -20.,   25.,   64.,  -80.,  100., -125.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556fd338",
   "metadata": {},
   "source": [
    "- ...generiamo 9 variabili, ovvero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dffbb859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'A^2', 'A B', 'B^2', 'A^3', 'A^2 B', 'A B^2', 'B^3']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c486f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede con un numero iniziale di variabili più alto?\n",
    "- Selezioniamo ad esempio dalle variabili X del dataset le 5 feature che avevano coefficiente non nullo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "272aae88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la lista delle feature da considerare è:\n",
    "Xsub_feats = [\"CHAS\", \"RM\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "# creo una selezione sia dal training che dal validation set\n",
    "Xsub_train = X_train[Xsub_feats]\n",
    "Xsub_val = X_val[Xsub_feats]\n",
    "# stampo il numero di colonne\n",
    "Xsub_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc54bc",
   "metadata": {},
   "source": [
    "- Generando le feature polinomiali con grado massimo 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bd2a09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be971110",
   "metadata": {},
   "source": [
    "- ...otteniamo 20 feature distinte!\n",
    "- Le feature includono infatti tutte le possibili coppie di variabili, oltre ai quadrati di ciascuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6dba46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAS',\n",
       " 'RM',\n",
       " 'PTRATIO',\n",
       " 'B',\n",
       " 'LSTAT',\n",
       " 'CHAS^2',\n",
       " 'CHAS RM',\n",
       " 'CHAS PTRATIO',\n",
       " 'CHAS B',\n",
       " 'CHAS LSTAT',\n",
       " 'RM^2',\n",
       " 'RM PTRATIO',\n",
       " 'RM B',\n",
       " 'RM LSTAT',\n",
       " 'PTRATIO^2',\n",
       " 'PTRATIO B',\n",
       " 'PTRATIO LSTAT',\n",
       " 'B^2',\n",
       " 'B LSTAT',\n",
       " 'LSTAT^2']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names(Xsub_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef4f85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando ulteriormente il grado, il numero di variabili cresce esponenzialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f55d23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da27babe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8df915b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe75be6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=6, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be98031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=7, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "458d47aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=8, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b0e93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Questa crescita è ancora più evidente con la matrice completa `X_train`, con 13 variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c18598f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665e0e2",
   "metadata": {},
   "source": [
    "- Generando le feature polinomiali con grado massimo 2 otteniamo 104 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e57b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda59da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando ulteriormente il grado, il numero di variabili cresce enormemente\n",
    "  - con grado 10 si supera il milione di variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89a3c724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e6a1a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2379"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59d51bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8567"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
    "poly.fit_transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20dfcbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27131"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=6, include_bias=False)\n",
    "poly.fit_transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690511a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- All'aumentare delle variabili, aumenta il tempo necessario per l'addestramento del modello\n",
    "- Prendiamo ad esempio come riferimento un modello ElasticNet polinomiale con standardizzazione delle feature generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9497dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_std_elasticnet(degree):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        (\"std\",  StandardScaler()),\n",
    "        (\"regr\", ElasticNet(alpha=0.5, l1_ratio=0.2))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b070a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Eseguiamo la prova su un modello di grado 2 sia col sottoinsieme di 5 feature indicato sopra che con tutte le feature\n",
    "- Usiamo il comando \"magico\" `%time` per riportare in output il tempo di esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02326358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.29 ms, sys: 2.13 ms, total: 5.42 ms\n",
      "Wall time: 4.59 ms\n",
      "   Mean squared error: 22.74\n",
      "       Relative error: 17.05512%\n",
      "R-squared coefficient: 0.69769\n"
     ]
    }
   ],
   "source": [
    "model = poly_std_elasticnet(2)\n",
    "%time model.fit(Xsub_train, y_train)\n",
    "print_eval(Xsub_val, y_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d268b522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.1 ms, sys: 66.2 ms, total: 93.3 ms\n",
      "Wall time: 35.9 ms\n",
      "   Mean squared error: 19.854\n",
      "       Relative error: 15.44921%\n",
      "R-squared coefficient: 0.73606\n"
     ]
    }
   ],
   "source": [
    "model = poly_std_elasticnet(2)\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966adcb",
   "metadata": {},
   "source": [
    "- L'addestramento richiede una frazione di secondo, anche per via del numero limitato di istanze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e423d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Verifichiamo ora cosa accade in entrambi i casi con grado 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74a8d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 164 ms, sys: 261 ms, total: 425 ms\n",
      "Wall time: 134 ms\n",
      "   Mean squared error: 16.714\n",
      "       Relative error: 14.62323%\n",
      "R-squared coefficient: 0.7778\n"
     ]
    }
   ],
   "source": [
    "model = poly_std_elasticnet(5)\n",
    "%time model.fit(Xsub_train, y_train)\n",
    "print_eval(Xsub_val, y_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0d4427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 s, sys: 436 ms, total: 2.46 s\n",
      "Wall time: 1.98 s\n",
      "   Mean squared error: 11.969\n",
      "       Relative error: 11.63031%\n",
      "R-squared coefficient: 0.84089\n"
     ]
    }
   ],
   "source": [
    "model = poly_std_elasticnet(5)\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4919b43",
   "metadata": {},
   "source": [
    "- L'accuratezza del modello migliora sensibilmente, ma **con tempi di addestramento molto superiori**\n",
    "  - più di 10 volte superiori con 5 feature\n",
    "  - più di 100 volte superiori con 13 feature\n",
    "  - con dataset più grandi, avremmo tempi di addestramento insostenibili"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c33e85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione con funzioni kernel\n",
    "\n",
    "- Nella regressione polinomiale si eseguono prodotti tra dati con dimensioni aggiunte e rappresentate esplicitamente\n",
    "- Le _funzioni kernel_ permettono di calcolare gli stessi prodotti senza calcolare esplicitamente le dimensioni aggiunte\n",
    "- Questo permette di ottenere **modelli non lineari senza l'aggiunta di variabili**\n",
    "- Esistono diverse funzioni kernel utilizzabili con diversi parametri impostabili\n",
    "- Ad esempio, il kernel polinomiale è definito dalla formula\n",
    "$$ K(\\mathbf{a},\\mathbf{b}) = \\left(\\mathbf{a}\\cdot\\mathbf{b}+c\\right)^d $$\n",
    "  - $d$ e $c$ sono parametri del kernel, in particolare $d$ è il grado del polinomio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174c2c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La classe `KernelRidge` implementa la regressione ridge con l'applicazione di una funzione kernel\n",
    "- Col parametro `kernel` si indica il tipo di kernel con una stringa, ad es. `\"poly\"` per un kernel polinomiale\n",
    "- Ulteriori parametri riguardano il kernel, per quello polinomiale sono `degree` ($d$) e `coef0` ($c$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae87ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.4 ms, sys: 69 ms, total: 102 ms\n",
      "Wall time: 33 ms\n",
      "   Mean squared error: 14.765\n",
      "       Relative error: 13.09973%\n",
      "R-squared coefficient: 0.80371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c55a46",
   "metadata": {},
   "source": [
    "- Abbiamo ottenuto un'accuratezza più elevata rispetto ai modelli lineari, ma in tempi molto più brevi rispetto alla regressione polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911b0e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Aumentando arbitrariamente il grado del polinomio, il tempo impiegato per l'addestramento non cambia\n",
    "  - in questo caso comunque un grado alto non porta ad un modello accurato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e11002a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 ms, sys: 56.6 ms, total: 89.2 ms\n",
      "Wall time: 26.2 ms\n",
      "   Mean squared error: 2.0188e+07\n",
      "       Relative error: 8417.85655%\n",
      "R-squared coefficient: -2.6838e+05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=15))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e984d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Va però ricordato che la complessità cresce quadraticamente col numero di istanze di training\n",
    "- Ad esempio, addestrando un modello su _tutti_ i dati invece che sul solo training set, quindi sul 50\\% di istanze in più..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fccfd7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.2 ms, sys: 154 ms, total: 206 ms\n",
      "Wall time: 62.6 ms\n",
      "   Mean squared error: 8.2617\n",
      "       Relative error: 8.99352%\n",
      "R-squared coefficient: 0.89017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])\n",
    "%time model.fit(X, y)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb8042",
   "metadata": {},
   "source": [
    "- ... il tempo necessario è circa il doppio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a1e85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo testare anche funzioni kernel diverse, ad esempio RBF (_radial basis function_)\n",
    "  - RBF ha valori tanto più elevati quanto più i valori X sono vicini a 0 (ovvero la media, usando dati standardizzati)\n",
    "- La funzione RBF ha la forma di una gaussiana, di cui si può impostare l'ampiezza col parametro `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b515846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.7 ms, sys: 77 ms, total: 107 ms\n",
      "Wall time: 32 ms\n",
      "   Mean squared error: 43.906\n",
      "       Relative error: 19.38425%\n",
      "R-squared coefficient: 0.41632\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"rbf\", gamma=0.01))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_val, y_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45866ead",
   "metadata": {},
   "source": [
    "- In questo caso specifico il kernel RBF non funziona bene tanto quanto il polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbbd338",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k-Fold Cross Validation\n",
    "\n",
    "- La _cross validation_ si riferisce in generale alla valutazione di un modello di predizione su dati differenti rispetto a quelli su cui è addestrato\n",
    "- Finora l'abbiamo svolta usando il semplice metodo _hold-out_\n",
    "  - i dati sono suddivisi casualmente in _training set_ e _validation set_ con proporzioni configurabili\n",
    "  - un modello è addestrato sul training set e validato sul validation set\n",
    "- Il metodo _k-fold_ è un'alternativa che permette una validazione più accurata\n",
    "  - i dati sono divisi causalmente in k gruppi (_fold_)\n",
    "  - ciascun gruppo è validato su un modello addestrato su tutti gli altri gruppi\n",
    "  - i risultati dei singoli test sono aggregati\n",
    "- scikit-learn fornisce un supporto generico per la cross-validation di modelli sia tramite k-fold che altri metodi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95a582",
   "metadata": {},
   "source": [
    "- Per prima cosa definiamo la metodologia di cross-validation da applicare\n",
    "- Usiamo ad esempio un oggetto della classe `KFold`\n",
    "  - il primo parametro è il numero di fold (k) da usare, prendiamo 5 come esempio\n",
    "  - specifichiamo inoltre che i dati sono distribuiti casualmente e il seed da usare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8bf9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb5408",
   "metadata": {},
   "source": [
    "- Definiamo un modello da validare, ad es. il modello kernel ridge visto sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a78a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec234e50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per eseguire la CV usiamo quindi la funzione `cross_validate`, a cui passiamo in input:\n",
    "  - la definizione di un modello, di cui viene addestrata una copia con la stessa configurazione per ciascun fold\n",
    "  - i dati, divisi come per `fit` in valori di variabili indipendenti (X) e dipendente (y)\n",
    "  - l'oggetto che definisce la strategia di CV, in questo caso l'istanza di `KFold`\n",
    "  - l'opzione `return_train_score=True` per ottenere la valutazione di ogni modello anche sui dati di addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82d72843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_result = cross_validate(model, X, y, cv=kf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48368663",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Otteniamo un dizionario con un vettore per ciascuna misura estratta, ciascuno ha un valore per ognuno dei 5 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7906cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03852463, 0.03081799, 0.03089452, 0.0287087 , 0.0285511 ]),\n",
       " 'score_time': array([0.0121448 , 0.01262403, 0.00940895, 0.00907612, 0.00944591]),\n",
       " 'test_score': array([0.79093529, 0.83709349, 0.69734727, 0.90845112, 0.7917183 ]),\n",
       " 'train_score': array([0.91333254, 0.90350452, 0.90330007, 0.8981712 , 0.90764729])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf12717",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per operare facilmente, raccogliamo i dati in un `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f361529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038525</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.790935</td>\n",
       "      <td>0.913333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030818</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.837093</td>\n",
       "      <td>0.903505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030895</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.697347</td>\n",
       "      <td>0.903300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028709</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.898171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028551</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.791718</td>\n",
       "      <td>0.907647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.038525    0.012145    0.790935     0.913333\n",
       "1  0.030818    0.012624    0.837093     0.903505\n",
       "2  0.030895    0.009409    0.697347     0.903300\n",
       "3  0.028709    0.009076    0.908451     0.898171\n",
       "4  0.028551    0.009446    0.791718     0.907647"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_table = pd.DataFrame(cv_result)\n",
    "cv_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c1725",
   "metadata": {},
   "source": [
    "- Per ognuno dei 5 fold vediamo riportati\n",
    "  - i secondi impiegati per l'addestramento (`fit_time`) e la validazione (`score_time`) del modello\n",
    "  - lo score calcolato su training set (`train_score`) e validation set (`test_score`)\n",
    "- Lo score è quello calcolato dal metodo `score` del modello, ovvero il coefficiente R²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4498ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per avere un dato generale sulla bontà del modello, possiamo calcolare media e deviazione standard degli score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c19225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.031499</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.805109</td>\n",
       "      <td>0.905191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.076967</td>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_score  train_score\n",
       "mean  0.031499    0.010540    0.805109     0.905191\n",
       "std   0.004082    0.001698    0.076967     0.005657"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_table.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dfa5f4",
   "metadata": {},
   "source": [
    "- Tale valutazione è più affidabile di quella col metodo hold-out, ottenuta da un singolo modello\n",
    "- Ci permette inoltre di valutare la \"robustezza\" del modello, ovvero quanto l'accuratezza sia stabile addestrandosi su set di dati diversi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4bd66f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 3: Cross-validation su modello kernel ridge\n",
    "\n",
    "- **(3a)** Definire un modello di regressione kernel ridge su feature standardizzate con kernel polinomiale di 3° grado e $\\alpha=10$\n",
    "- **(3b)** Eseguire la cross-validation del modello, utilizzando 5 fold dell'intero set di dati (`X` e `y`) generati dall'oggetto `kf` definito sopra\n",
    "- **(3c)** Calcolare la media e la deviazione standard dei punteggi R² ottenuti dalla validazione di ciascun fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49faf63b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ricerca degli iperparametri con grid search\n",
    "\n",
    "- Sui modelli utilizzati finora abbiamo impostato manualmente i valori di diversi iperparametri\n",
    "  - grado della regressione polinomiale, peso della regolarizzazione, ...\n",
    "- L'accuratezza del modello può dipendere fortemente da questi valori\n",
    "- Scelto un generico modello da utilizzare (es. regressione polinomiale o kernel ridge), vorremmo **individuare i valori degli iperparametri che ne massimizzino l'accuratezza**\n",
    "- scikit-learn fornisce un supporto per effettuare una ricerca \"a griglia\" (_grid search_) sui valori degli iperparametri, effettuando la cross validation di un modello con diverse configurazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b754e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Consideriamo ad esempio un modello _elastic net_ di cui fissiamo arbitrariamente il parametro `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dae26b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(l1_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830d609",
   "metadata": {},
   "source": [
    "- Vorremmo trovare il migliore valore possibile del parametro `alpha` tra un insieme di valori possibili, ad esempio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2612d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_alphas = [  0.01,    0.1,     1,    10]\n",
    "# ovvero\n",
    "candidate_alphas = [10**-2, 10**-1, 10**0, 10**1]\n",
    "# che si può ottenere con\n",
    "candidate_alphas = np.logspace(-2, 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f412b",
   "metadata": {},
   "source": [
    "- Creiamo ora la _griglia_ dei parametri, ovvero un dizionario in cui associamo ai nomi dei parametri variabili i valori che possono assumere\n",
    "- In questo caso abbiamo un unico parametro variabile, `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fa6d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"alpha\": candidate_alphas}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9a130",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Definiamo ora un modello `GridSearchCV` indicando\n",
    "  - il modello \"base\" con i parametri fissati a priori\n",
    "  - la griglia dei parametri variabili\n",
    "  - il metodo `cv` di cross validation da usare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "007853b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(model, grid, cv=kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d40a62",
   "metadata": {},
   "source": [
    "- Come per i modelli base, usiamo il metodo `fit` per eseguire l'addestramento, passando la matrice X e il vettore y\n",
    "- Per ogni valore possibile di `alpha`, scikit-learn esegue la cross-validation per calcolare il punteggio R² medio del modello con quel valore di `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98d7f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c6899",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In seguito ai test, il modello impostato viene (di default) riaddestrato su tutti i dati forniti, usando gli iperparametri che han dato il miglior punteggio medio\n",
    "- Il modello finale è accessibile all'attributo `gs_best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3bcff963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=0.2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b588b2",
   "metadata": {},
   "source": [
    "- Dall'attributo `best_params_` possiamo vedere quali sono i valori selezionati dalla griglia degli iperparametri per tale modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd708f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f422e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- L'oggetto `GridSearchCV` addestrato può essere usato come un normale modello di predizione, le chiamate a `predict` e altri metodi sono girate al `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c02950a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.35759953])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prezzo predetto per la prima riga del validation set\n",
    "gs.predict(X_val.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c80d3a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.35759953])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalente a\n",
    "gs.best_estimator_.predict(X_val.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c0841",
   "metadata": {},
   "source": [
    "- Possiamo valutare il modello sul validation set \"esterno\", non utilizzato nella grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26b5e350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean squared error: 21.905\n",
      "       Relative error: 16.80121%\n",
      "R-squared coefficient: 0.7088\n"
     ]
    }
   ],
   "source": [
    "print_eval(X_val, y_val, gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c9e11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- L'attributo `cv_results_` fornisce risultati dettagliati su tutti gli iperparametri testati\n",
    "- Come per `cross_validate`, raccogliamo i risultati in un `DataFrame` per visualizzarli meglio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "333adc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.728071</td>\n",
       "      <td>0.483786</td>\n",
       "      <td>0.645836</td>\n",
       "      <td>0.711862</td>\n",
       "      <td>0.801124</td>\n",
       "      <td>0.674136</td>\n",
       "      <td>0.107231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.727252</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0.637157</td>\n",
       "      <td>0.721205</td>\n",
       "      <td>0.800228</td>\n",
       "      <td>0.676539</td>\n",
       "      <td>0.103639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>0.523966</td>\n",
       "      <td>0.594603</td>\n",
       "      <td>0.670194</td>\n",
       "      <td>0.761741</td>\n",
       "      <td>0.652905</td>\n",
       "      <td>0.084740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'alpha': 10.0}</td>\n",
       "      <td>0.624769</td>\n",
       "      <td>0.373641</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>0.539693</td>\n",
       "      <td>0.623149</td>\n",
       "      <td>0.546709</td>\n",
       "      <td>0.092296</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.005117      0.001650         0.003252        0.000595        0.01   \n",
       "1       0.003867      0.001181         0.002479        0.000790         0.1   \n",
       "2       0.003206      0.000407         0.001909        0.000255         1.0   \n",
       "3       0.002807      0.000233         0.001760        0.000049        10.0   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.01}           0.728071           0.483786           0.645836   \n",
       "1   {'alpha': 0.1}           0.727252           0.496850           0.637157   \n",
       "2   {'alpha': 1.0}           0.714022           0.523966           0.594603   \n",
       "3  {'alpha': 10.0}           0.624769           0.373641           0.572294   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.711862           0.801124         0.674136        0.107231   \n",
       "1           0.721205           0.800228         0.676539        0.103639   \n",
       "2           0.670194           0.761741         0.652905        0.084740   \n",
       "3           0.539693           0.623149         0.546709        0.092296   \n",
       "\n",
       "   rank_test_score  \n",
       "0                2  \n",
       "1                1  \n",
       "2                3  \n",
       "3                4  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048fc14",
   "metadata": {},
   "source": [
    "I dati riportati per ciascun test includono:\n",
    "- `{mean|std}_{fit|score}_time`: media/dev. standard dei tempi di addestramento/valutazione sui diversi fold\n",
    "- `param_X`: valore del parametro X\n",
    "- `params`: dizionario col valore di tutti i parametri\n",
    "- `splitN_test_score`: punteggio della valutazione sull'N-esimo fold\n",
    "- `{mean|std}_test_score`: media/dev. standard dei punteggi sui diversi fold\n",
    "- `rank_test_score`: ranking del punteggio, 1 è il migliore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45f0812",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Cosa succede con più iperparametri variabili?\n",
    "- Impostiamo ad esempio sia 3 valori possibili per `alpha` che 3 valori possibili per `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aa5b261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet()\n",
    "grid = {\n",
    "    \"alpha\":    [0.1, 1, 10],\n",
    "    \"l1_ratio\": [0.1, 0.2, 0.3]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f830b2d",
   "metadata": {},
   "source": [
    "- Visualizzo i risultati ordinati per punteggio R² medio decrescente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80568b5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.727791</td>\n",
       "      <td>0.499753</td>\n",
       "      <td>0.636757</td>\n",
       "      <td>0.721171</td>\n",
       "      <td>0.800223</td>\n",
       "      <td>0.677139</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.2}</td>\n",
       "      <td>0.727252</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0.637157</td>\n",
       "      <td>0.721205</td>\n",
       "      <td>0.800228</td>\n",
       "      <td>0.676539</td>\n",
       "      <td>0.103639</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.726624</td>\n",
       "      <td>0.493642</td>\n",
       "      <td>0.637503</td>\n",
       "      <td>0.721081</td>\n",
       "      <td>0.800186</td>\n",
       "      <td>0.675807</td>\n",
       "      <td>0.104646</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.714960</td>\n",
       "      <td>0.526437</td>\n",
       "      <td>0.595148</td>\n",
       "      <td>0.670794</td>\n",
       "      <td>0.763423</td>\n",
       "      <td>0.654152</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.2}</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>0.523966</td>\n",
       "      <td>0.594603</td>\n",
       "      <td>0.670194</td>\n",
       "      <td>0.761741</td>\n",
       "      <td>0.652905</td>\n",
       "      <td>0.084740</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.714237</td>\n",
       "      <td>0.521933</td>\n",
       "      <td>0.594699</td>\n",
       "      <td>0.669538</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.652037</td>\n",
       "      <td>0.084850</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.638007</td>\n",
       "      <td>0.397883</td>\n",
       "      <td>0.577252</td>\n",
       "      <td>0.557198</td>\n",
       "      <td>0.655982</td>\n",
       "      <td>0.565264</td>\n",
       "      <td>0.091374</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.2}</td>\n",
       "      <td>0.624769</td>\n",
       "      <td>0.373641</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>0.539693</td>\n",
       "      <td>0.623149</td>\n",
       "      <td>0.546709</td>\n",
       "      <td>0.092296</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.614417</td>\n",
       "      <td>0.357906</td>\n",
       "      <td>0.570172</td>\n",
       "      <td>0.529856</td>\n",
       "      <td>0.607627</td>\n",
       "      <td>0.535995</td>\n",
       "      <td>0.094024</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.005770      0.000322         0.003815        0.000422         0.1   \n",
       "1       0.005260      0.000362         0.003425        0.000808         0.1   \n",
       "2       0.003544      0.000410         0.001974        0.000356         0.1   \n",
       "3       0.002546      0.000056         0.001573        0.000081           1   \n",
       "4       0.002571      0.000069         0.001557        0.000045           1   \n",
       "5       0.002503      0.000042         0.001578        0.000099           1   \n",
       "6       0.002510      0.000105         0.001670        0.000193          10   \n",
       "7       0.002620      0.000114         0.001590        0.000095          10   \n",
       "8       0.002507      0.000098         0.001588        0.000053          10   \n",
       "\n",
       "  param_l1_ratio                           params  split0_test_score  \\\n",
       "0            0.1  {'alpha': 0.1, 'l1_ratio': 0.1}           0.727791   \n",
       "1            0.2  {'alpha': 0.1, 'l1_ratio': 0.2}           0.727252   \n",
       "2            0.3  {'alpha': 0.1, 'l1_ratio': 0.3}           0.726624   \n",
       "3            0.1    {'alpha': 1, 'l1_ratio': 0.1}           0.714960   \n",
       "4            0.2    {'alpha': 1, 'l1_ratio': 0.2}           0.714022   \n",
       "5            0.3    {'alpha': 1, 'l1_ratio': 0.3}           0.714237   \n",
       "6            0.1   {'alpha': 10, 'l1_ratio': 0.1}           0.638007   \n",
       "7            0.2   {'alpha': 10, 'l1_ratio': 0.2}           0.624769   \n",
       "8            0.3   {'alpha': 10, 'l1_ratio': 0.3}           0.614417   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.499753           0.636757           0.721171           0.800223   \n",
       "1           0.496850           0.637157           0.721205           0.800228   \n",
       "2           0.493642           0.637503           0.721081           0.800186   \n",
       "3           0.526437           0.595148           0.670794           0.763423   \n",
       "4           0.523966           0.594603           0.670194           0.761741   \n",
       "5           0.521933           0.594699           0.669538           0.759777   \n",
       "6           0.397883           0.577252           0.557198           0.655982   \n",
       "7           0.373641           0.572294           0.539693           0.623149   \n",
       "8           0.357906           0.570172           0.529856           0.607627   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.677139        0.102714                1  \n",
       "1         0.676539        0.103639                2  \n",
       "2         0.675807        0.104646                3  \n",
       "3         0.654152        0.084507                4  \n",
       "4         0.652905        0.084740                5  \n",
       "5         0.652037        0.084850                6  \n",
       "6         0.565264        0.091374                7  \n",
       "7         0.546709        0.092296                8  \n",
       "8         0.535995        0.094024                9  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac520c",
   "metadata": {},
   "source": [
    "- scikit-learn ha generato e testato **tutte le combinazioni possibili** dei valori degli iperparametri, in tutto 3×3 = 9 configurazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34876e33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid search su pipeline\n",
    "\n",
    "- Possiamo usare `GridSearchCV` anche con una pipeline, testando diversi valori per i parametri dei singoli componenti (filtri e modello)\n",
    "- Consideriamo ad esempio un modello polinomiale con regolarizzazione L2, su cui sono variabili\n",
    "  - il grado del polinomio (attributo `degree` del filtro `poly`)\n",
    "  - il peso della regolarizzazione (attributo `alpha` del modello `regr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3fff564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"poly\",  PolynomialFeatures(include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea612e9b",
   "metadata": {},
   "source": [
    "- Per riferirsi ai parametri dei singoli componenti, usiamo la notazione `componente__parametro` _(con DUE underscore in mezzo)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed273500",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"poly__degree\": [2, 3],      # <- grado polinomio\n",
    "    \"regr__alpha\":  [0.1, 1, 10] # <- regolarizzazione\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e47fbe",
   "metadata": {},
   "source": [
    "- Il resto del funzionamento rimane invariato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75f2f603",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_poly__degree</th>\n",
       "      <th>param_regr__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'poly__degree': 2, 'regr__alpha': 1}</td>\n",
       "      <td>0.835447</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.802240</td>\n",
       "      <td>0.810611</td>\n",
       "      <td>0.882463</td>\n",
       "      <td>0.785450</td>\n",
       "      <td>0.098521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030462</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'poly__degree': 2, 'regr__alpha': 10}</td>\n",
       "      <td>0.842239</td>\n",
       "      <td>0.594859</td>\n",
       "      <td>0.750900</td>\n",
       "      <td>0.795789</td>\n",
       "      <td>0.856246</td>\n",
       "      <td>0.768007</td>\n",
       "      <td>0.094172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030712</td>\n",
       "      <td>0.004690</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'poly__degree': 2, 'regr__alpha': 0.1}</td>\n",
       "      <td>0.824409</td>\n",
       "      <td>0.648065</td>\n",
       "      <td>0.850516</td>\n",
       "      <td>0.816894</td>\n",
       "      <td>0.493138</td>\n",
       "      <td>0.726604</td>\n",
       "      <td>0.136929</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031003</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'poly__degree': 3, 'regr__alpha': 10}</td>\n",
       "      <td>0.853895</td>\n",
       "      <td>0.454814</td>\n",
       "      <td>0.773790</td>\n",
       "      <td>0.748621</td>\n",
       "      <td>0.333358</td>\n",
       "      <td>0.632895</td>\n",
       "      <td>0.201753</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029644</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'poly__degree': 3, 'regr__alpha': 1}</td>\n",
       "      <td>0.852441</td>\n",
       "      <td>0.568150</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.775824</td>\n",
       "      <td>-3.047350</td>\n",
       "      <td>-0.011207</td>\n",
       "      <td>1.521113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030254</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'poly__degree': 3, 'regr__alpha': 0.1}</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.648950</td>\n",
       "      <td>0.784034</td>\n",
       "      <td>-3.348237</td>\n",
       "      <td>-0.111696</td>\n",
       "      <td>1.618947</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       0.025326      0.003006         0.004403        0.001998   \n",
       "2       0.030462      0.003201         0.004411        0.002281   \n",
       "0       0.030712      0.004690         0.004241        0.001379   \n",
       "5       0.031003      0.003968         0.006002        0.001280   \n",
       "4       0.029644      0.001920         0.006447        0.000761   \n",
       "3       0.030254      0.001244         0.006951        0.000270   \n",
       "\n",
       "  param_poly__degree param_regr__alpha  \\\n",
       "1                  2                 1   \n",
       "2                  2                10   \n",
       "0                  2               0.1   \n",
       "5                  3                10   \n",
       "4                  3                 1   \n",
       "3                  3               0.1   \n",
       "\n",
       "                                    params  split0_test_score  \\\n",
       "1    {'poly__degree': 2, 'regr__alpha': 1}           0.835447   \n",
       "2   {'poly__degree': 2, 'regr__alpha': 10}           0.842239   \n",
       "0  {'poly__degree': 2, 'regr__alpha': 0.1}           0.824409   \n",
       "5   {'poly__degree': 3, 'regr__alpha': 10}           0.853895   \n",
       "4    {'poly__degree': 3, 'regr__alpha': 1}           0.852441   \n",
       "3  {'poly__degree': 3, 'regr__alpha': 0.1}           0.692042   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.596491           0.802240           0.810611           0.882463   \n",
       "2           0.594859           0.750900           0.795789           0.856246   \n",
       "0           0.648065           0.850516           0.816894           0.493138   \n",
       "5           0.454814           0.773790           0.748621           0.333358   \n",
       "4           0.568150           0.794898           0.775824          -3.047350   \n",
       "3           0.664729           0.648950           0.784034          -3.348237   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.785450        0.098521                1  \n",
       "2         0.768007        0.094172                2  \n",
       "0         0.726604        0.136929                3  \n",
       "5         0.632895        0.201753                4  \n",
       "4        -0.011207        1.521113                5  \n",
       "3        -0.111696        1.618947                6  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(model, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646317e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Nella pipeline possiamo inoltre impostare un intero componente come parametro variabile, con la possibilità di rimuoverlo impostandolo a `None`\n",
    "- Possiamo ad esempio testare un modello con e senza standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "074da37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_regr__alpha</th>\n",
       "      <th>param_scale</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>{'regr__alpha': 1, 'scale': StandardScaler()}</td>\n",
       "      <td>0.735767</td>\n",
       "      <td>0.495302</td>\n",
       "      <td>0.657167</td>\n",
       "      <td>0.720101</td>\n",
       "      <td>0.800925</td>\n",
       "      <td>0.681853</td>\n",
       "      <td>0.103883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.1</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>{'regr__alpha': 0.1, 'scale': StandardScaler()}</td>\n",
       "      <td>0.735121</td>\n",
       "      <td>0.495993</td>\n",
       "      <td>0.656523</td>\n",
       "      <td>0.720110</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.681776</td>\n",
       "      <td>0.103648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>10</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>{'regr__alpha': 10, 'scale': StandardScaler()}</td>\n",
       "      <td>0.741449</td>\n",
       "      <td>0.487396</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.718528</td>\n",
       "      <td>0.798668</td>\n",
       "      <td>0.681668</td>\n",
       "      <td>0.106525</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'regr__alpha': 0.1, 'scale': None}</td>\n",
       "      <td>0.734675</td>\n",
       "      <td>0.494498</td>\n",
       "      <td>0.655446</td>\n",
       "      <td>0.718577</td>\n",
       "      <td>0.801852</td>\n",
       "      <td>0.681009</td>\n",
       "      <td>0.104244</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'regr__alpha': 1, 'scale': None}</td>\n",
       "      <td>0.730686</td>\n",
       "      <td>0.487010</td>\n",
       "      <td>0.649269</td>\n",
       "      <td>0.712555</td>\n",
       "      <td>0.801934</td>\n",
       "      <td>0.676291</td>\n",
       "      <td>0.106412</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>{'regr__alpha': 10, 'scale': None}</td>\n",
       "      <td>0.726584</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.641675</td>\n",
       "      <td>0.719819</td>\n",
       "      <td>0.801424</td>\n",
       "      <td>0.675606</td>\n",
       "      <td>0.106333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       0.005952      0.000248         0.002513        0.000128   \n",
       "1       0.006078      0.000081         0.002504        0.000084   \n",
       "5       0.005859      0.000128         0.002440        0.000123   \n",
       "0       0.007792      0.003227         0.003392        0.001026   \n",
       "2       0.003613      0.000091         0.002297        0.000081   \n",
       "4       0.003588      0.000105         0.002234        0.000111   \n",
       "\n",
       "  param_regr__alpha       param_scale  \\\n",
       "3                 1  StandardScaler()   \n",
       "1               0.1  StandardScaler()   \n",
       "5                10  StandardScaler()   \n",
       "0               0.1              None   \n",
       "2                 1              None   \n",
       "4                10              None   \n",
       "\n",
       "                                            params  split0_test_score  \\\n",
       "3    {'regr__alpha': 1, 'scale': StandardScaler()}           0.735767   \n",
       "1  {'regr__alpha': 0.1, 'scale': StandardScaler()}           0.735121   \n",
       "5   {'regr__alpha': 10, 'scale': StandardScaler()}           0.741449   \n",
       "0              {'regr__alpha': 0.1, 'scale': None}           0.734675   \n",
       "2                {'regr__alpha': 1, 'scale': None}           0.730686   \n",
       "4               {'regr__alpha': 10, 'scale': None}           0.726584   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.495302           0.657167           0.720101           0.800925   \n",
       "1           0.495993           0.656523           0.720110           0.801136   \n",
       "5           0.487396           0.662300           0.718528           0.798668   \n",
       "0           0.494498           0.655446           0.718577           0.801852   \n",
       "2           0.487010           0.649269           0.712555           0.801934   \n",
       "4           0.488528           0.641675           0.719819           0.801424   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.681853        0.103883                1  \n",
       "1         0.681776        0.103648                2  \n",
       "5         0.681668        0.106525                3  \n",
       "0         0.681009        0.104244                4  \n",
       "2         0.676291        0.106412                5  \n",
       "4         0.675606        0.106333                6  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", None),   # uso None come segnaposto\n",
    "    (\"regr\",  Ridge())\n",
    "])\n",
    "grid = {\n",
    "    # scale = standardizzazione oppure nulla\n",
    "    \"scale\": [None, StandardScaler()],\n",
    "    \"regr__alpha\": [0.1, 1, 10]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kf)\n",
    "gs.fit(X_train, y_train);\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ef368",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 4: Grid search su regressione kernel ridge\n",
    "\n",
    "- **(4a)** Creare una funzione `grid_test` che, presi in input un modello e una griglia di parametri\n",
    "  - esegua una grid search con `X_train`, `y_train` come dati di addestramento con modello e parametri forniti, usando cross-validation a 5 fold\n",
    "  - stampi (`print(...)`) il dizionario con gli iperparametri selezionati del modello migliore\n",
    "  - stampi le misure di accuratezza (`print_eval`) sui dati `X_val`, `y_val`\n",
    "- **(4b)** Testare con la funzione sopra un modello di regressione elastic net polinomiale con\n",
    "  - grado 2 o 3\n",
    "  - standardizzazione delle feature generate\n",
    "  - `alpha` pari a 0.1, 1 o 10\n",
    "  - `l1_ratio` pari a 0.1, 0.25 o 0.5\n",
    "- **(4c)** Testare con la funzione sopra un modello kernel ridge con\n",
    "  - standardizzazione dei dati\n",
    "  - kernel polinomiale di grado compreso tra 2 e 10\n",
    "  - `alpha` (regolarizzazione) pari a 0.01, 0.1, 1 o 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "337702b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_test(model, grid):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e42e19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested cross-validation\n",
    "\n",
    "- Negli esercizi sopra abbiamo validato il risultato finale della grid search su un validation set separato\n",
    "- In altre parole, abbiamo usato il metodo k-fold per l'ottimizzazione degli iperparametri, mentre abbiamo usato hold-out per la validazione finale\n",
    "- La _nested k-fold cross-validation_ prevede che siano generati **k fold \"esterni\"** su tutti i dati disponibili e che **per ciascuno** si esegua il tuning degli iperparametri con una cross validation \"interna\" usando le parti di training dei fold esterni\n",
    "- I metodi di cross validation esterna ed interna possono differire, ad es. avendo un diverso numero di fold\n",
    "- Ipotizziamo ad esempio di usare 3 fold esterni e 5 interni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0961d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(3, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455b366",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 5: Nested cross validation\n",
    "\n",
    "- **(5a)** Completare l'implementazione una funzione `nested_cv` che esegua la nested cross validation\n",
    "  - predisporre una lista vuota in cui salvare i punteggi ottenuti su ogni fold esterno\n",
    "  - usare un ciclo `for` per iterare tutti i fold esterni (T, V) del dataset `X`, `y`\n",
    "    - usare il metodo `split` di `outer_cv`, che fornisce per ogni fold gli indici delle istanze di training e di validation\n",
    "  - su ciascun fold esterno, eseguire la grid search con modello e parametri dati in ingresso alla funzione sui dati T, applicando `inner_cv` come cross validation\n",
    "  - per ogni grid search, salvare nella lista di punteggi il R² ottenuto dalla validazione del modello finale sui dati V\n",
    "  - restituire la lista alla fine del ciclo\n",
    "- **(5b)** Testare la funzione su uno dei modelli usati sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca6b1235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(model, grid):\n",
    "    results = []\n",
    "    for train_indices, val_indices in outer_cv.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "        X_val, y_val = X.iloc[val_indices], y.iloc[val_indices]\n",
    "        ...\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469f696",
   "metadata": {},
   "source": [
    "## Appendice: Disabilitare i warning\n",
    "\n",
    "- Alcuni dei modelli utilizzati possono mostrare dei warning nel caso l'addestramento non riesca a convergere\n",
    "  - questi warning possono essere ripetuti più volte durante cross validation e grid search\n",
    "- Eseguire il seguente codice per non stampare questa categoria di warning (adattare per altre simili, ad es. `DeprecationWarning`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d77b9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
